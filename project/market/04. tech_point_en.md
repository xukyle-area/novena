# Tampines Project Interview Preparation - Technical Points Quick Reference

## üìä Project Core Metrics

| Metric                    | Value                                           |
| ------------------------- | ----------------------------------------------- |
| **Project Name**          | Tampines Real-time Financial Market Data System |
| **Core Technology**       | Apache Flink 1.17.2 + Kafka 3.1.2 + Redis       |
| **Module Count**          | 3 (common, flink, outer)                        |
| **Flink Job Count**       | 3 (OrderbookJob, TickerJob, CandleJob)          |
| **Data Latency**          | Millisecond-level (<100ms)                      |
| **Parallelism**           | 1 (dev env, scalable to 32+ in production)      |
| **State Backend**         | RocksDB                                         |
| **Checkpoint Interval**   | 60 seconds                                      |
| **Data Precision**        | BigDecimal (financial-grade)                    |
| **Order Book Resolution** | 1, 5, 10, 100 √ó tickSize                        |

---

## üèóÔ∏è System Architecture Quick Reference

### Three-Tier Architecture
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  market-outer   ‚îÇ  WebSocket data ingestion
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ Kafka Topics
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  market-flink   ‚îÇ  Flink stream processing
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ Redis
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ market-common   ‚îÇ  Common foundation components
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Data Flow
```
External Exchange ‚Üí WebSocket ‚Üí market-outer ‚Üí Kafka ‚Üí Flink Jobs ‚Üí Redis ‚Üí Frontend/API
```

### Kafka Topics
- `order` - Order data
- `trade` - Trade data  
- `quote` - Market quote data

### Redis Keys
- `orderbook:{resolution}:{contractId}` - Order book
- `ticker:{contractId}` - 24-hour market data
- `candle:{period}:{contractId}` - Candlestick data

---

## üíª Core Code Quick Reference

### OrderBookProcessor Key Methods

#### 1. State Initialization
```java
MapState<BigDecimal, BigDecimal> bidState;  // Bids
MapState<BigDecimal, BigDecimal> askState;  // Asks
```

#### 2. Order Processing
```java
processElement(Order order, Context ctx, Collector<OrderBook> out)
‚îú‚îÄ Price grouping: groupedPrice = groupPrice(price, grouping)
‚îú‚îÄ Select state: sideState = (BID) ? bidState : askState
‚îú‚îÄ Update state:
‚îÇ  ‚îú‚îÄ INSERT: sideState.put(price, currentQty + newQty)
‚îÇ  ‚îî‚îÄ DELETE: sideState.remove(price) or update(price, currentQty - qty)
‚îî‚îÄ Register timer: timer = currentTime + 1000ms
```

#### 3. Timer Trigger
```java
onTimer(long timestamp, OnTimerContext ctx, Collector<OrderBook> out)
‚îú‚îÄ Iterate bidState.entries() ‚Üí orderBook.getBids()
‚îú‚îÄ Iterate askState.entries() ‚Üí orderBook.getAsks()
‚îú‚îÄ Set metadata: contractId, grouping, market
‚îî‚îÄ Output: out.collect(orderBook)
```

#### 4. Price Grouping Algorithm
```java
groupPrice(BigDecimal price, double grouping)
  = floor(price / grouping) * grouping
  
Example: price=100.23, grouping=2.5
     ‚Üí floor(100.23 / 2.5) * 2.5 = 100.0
```

### TickerJob Key Configuration
```java
keyedStream
  .window(SlidingEventTimeWindows.of(
    Time.hours(24),    // Window size
    Time.seconds(1)))  // Slide step
  .aggregate(new TickerAggregator(), new TickerProcessor())
  .addSink(new TickerSink())
```

---

## üîß Flink Core Knowledge Quick Reference

### State Type Comparison

| State Type           | Characteristics                | Usage in Project                   |
| -------------------- | ------------------------------ | ---------------------------------- |
| **MapState<K, V>**   | Map structure, efficient query | ‚úÖ OrderBookProcessor (bids/asks)   |
| **ValueState<T>**    | Single value storage           | Can be used for dedup (lastSeenId) |
| **ListState<T>**     | List storage                   | Not used                           |
| **ReducingState<T>** | Accumulating                   | Not used                           |
| **AggregatingState** | Complex aggregation            | TickerAggregator built-in          |

### Checkpoint Mechanism

```
1. JobManager injects Barrier
   ‚Üì
2. Barrier propagates with data flow
   ‚Üì
3. Operator saves state snapshot when receiving Barrier
   ‚Üì
4. Snapshot persisted to external storage (HDFS/S3)
   ‚Üì
5. All operators complete ‚Üí Checkpoint success
   ‚Üì
6. Kafka Offset also saved
   ‚Üì
On failure, recover from most recent Checkpoint
```

### Exactly-Once Implementation

| Layer           | Implementation Method                                      |
| --------------- | ---------------------------------------------------------- |
| **Source**      | Kafka manually manages Offset, Checkpoint records position |
| **Computation** | Barrier alignment + State snapshot                         |
| **Sink**        | Redis SET idempotent write                                 |

---

## üöÄ Performance Optimization Quick Reference

### Optimization Methods (6 Categories)

#### 1. Parallelism Optimization
```java
// Different parallelism for different operators
source.setParallelism(4)
  .process(...).setParallelism(2)
  .addSink(...).setParallelism(4)
```

#### 2. State Optimization
```java
// RocksDB StateBackend
see.setStateBackend(new RocksDBStateBackend("hdfs://..."));

// Incremental Checkpoint
see.getCheckpointConfig().enableIncrementalCheckpoints(true);

// State TTL
StateTtlConfig.newBuilder(Time.days(1)).build();
```

#### 3. Network Optimization
```java
see.getConfig().setNetworkBufferTimeout(100);  // 100ms
```

#### 4. Operator Chain Optimization
```java
see.disableOperatorChaining();  // For debugging
stream.map(...).startNewChain();  // Force break
```

#### 5. Data Skew Handling
```java
// Add random prefix ‚Üí two-stage aggregation
.map(data -> (random + "_" + key, data))
.keyBy(0).reduce(...)
.map(data -> (key, data))
.keyBy(0).reduce(...)
```

#### 6. Async IO
```java
AsyncDataStream.unorderedWait(
  stream,
  new AsyncRedisFunction(),
  1000, TimeUnit.MILLISECONDS,
  100  // Async capacity
)
```

### Optimization Practices in Project
1. ‚úÖ **Price grouping algorithm** - Reduce state count
2. ‚úÖ **Delete levels with quantity 0** - Avoid state accumulation
3. ‚úÖ **RocksDB StateBackend** - Support large state
4. üî≤ Async Redis write (can optimize)
5. üî≤ Incremental output (can optimize)

---

## üêõ Failure Troubleshooting Quick Reference

### Order Book Not Updating - Troubleshooting Process
```
1. Confirm phenomenon
   redis-cli GET orderbook:1:1  # Check timestamp

2. Check Flink job
   http://localhost:8081  # Web UI

3. Check logs
   tail -f flink-*-taskexecutor-*.log
   grep "ERROR" *.log

4. Check Kafka consumption
   kafka-consumer-groups.sh --describe --group orderbook

5. Check market-outer
   tail -f market-outer.log

6. Check dependent services
   redis-cli PING
   kafka-broker-api-versions.sh --bootstrap-server localhost:9092
```

### Common Failure Causes

| Symptom                     | Possible Cause           | Solution                                 |
| --------------------------- | ------------------------ | ---------------------------------------- |
| **Order book not updating** | Flink job crashed        | Check logs, restart job                  |
|                             | Kafka disconnected       | Restart Kafka, check network             |
|                             | WebSocket disconnected   | Restart market-outer                     |
| **Memory OOM**              | State too large          | Increase memory/RocksDB/State cleanup    |
| **High processing latency** | Data skew                | Add random prefix/custom partitioner     |
|                             | Insufficient parallelism | Increase parallelism                     |
| **Checkpoint failure**      | Timeout                  | Increase timeout/incremental Checkpoint  |
|                             | Disk full                | Clean disk/expand capacity               |
| **Redis write failure**     | Connection pool full     | Increase connection pool/retry mechanism |
|                             | Memory full              | Expand/set expiration time               |

---

## üìà Monitoring Metrics Quick Reference

### Flink Web UI (port 8081)

| Page             | Focus Metrics                    |
| ---------------- | -------------------------------- |
| **Overview**     | TaskManager count, slot usage    |
| **Jobs**         | Running status, duration         |
| **Task Metrics** | Records/s, Bytes/s, Backpressure |
| **Checkpoints**  | Success rate, duration, size     |

### Key Metrics

| Metric                  | Meaning              | Normal Range         |
| ----------------------- | -------------------- | -------------------- |
| **Throughput**          | Records/s            | Business-dependent   |
| **Latency**             | End-to-end latency   | <100ms               |
| **Backpressure**        | Backpressure (0-1)   | <0.5                 |
| **Checkpoint Duration** | Checkpoint time cost | <10s                 |
| **State Size**          | State size           | Stable growth/stable |

### Custom Metrics Example
```java
Counter processedOrders = metricGroup.counter("processed_orders");
Meter processingRate = metricGroup.meter("processing_rate", new MeterView(60));
Gauge stateSize = metricGroup.gauge("state_size", () -> getStateSize());
```

---

## üéØ High-Frequency Interview Questions Quick Reference

### Core Questions (Must Ask)

| Question                       | Keyword Answer                                                      |
| ------------------------------ | ------------------------------------------------------------------- |
| **Project Introduction**       | Real-time financial data, Flink+Kafka+Redis, order book maintenance |
| **Why Choose Flink**           | Native stream processing, MapState, exactly-once, low latency       |
| **How to Maintain Order Book** | KeyBy partition, MapState storage, price grouping, timer output     |
| **How to Ensure Consistency**  | Checkpoint, exactly-once semantics, idempotent write                |
| **Challenges Encountered**     | State too large OOM ‚Üí price grouping + RocksDB                      |
| **Performance Optimization**   | Parallelism, async IO, state cleanup, data skew                     |
| **Failure Handling**           | Restart strategy, retry mechanism, monitoring alerts                |

### Technical Deep Dive (Possible Questions)

#### Flink State Related
- What State types? (5 types)
- How to use MapState? (get/put/remove/entries)
- Where is State stored? (memory/RocksDB/HDFS)
- What is State TTL? (Auto-clean expired state)

#### Checkpoint Related
- Checkpoint mechanism? (Barrier alignment, snapshot, persistence)
- How to configure? (enableCheckpointing, EXACTLY_ONCE)
- How to recover on failure? (Recover state and Offset from recent Checkpoint)

#### Watermark Related
- What is it? (Timestamp for handling out-of-order data)
- Used in project? (OrderbookJob no, TickerJob should)
- Why not use? (ProcessingTime + timer, simplified logic)

#### Data Skew
- How to identify? (SubTask processing volume difference large)
- How to solve? (Random prefix, custom partitioner, split processing)

---

## üìù Code Interview Quick Reference

### Possible Hand-Written Code Directions

#### 1. Implement Simple MapState Operation
```java
public class SimpleProcessor 
    extends KeyedProcessFunction<String, Event, Result> {
    
    private MapState<String, Long> countState;

    @Override
    public void open(Configuration parameters) {
        countState = getRuntimeContext().getMapState(
            new MapStateDescriptor<>("counts", String.class, Long.class));
    }

    @Override
    public void processElement(Event event, Context ctx, Collector<Result> out) 
        throws Exception {
        String key = event.getKey();
        Long count = countState.get(key);
        count = (count == null) ? 1L : count + 1L;
        countState.put(key, count);
        
        out.collect(new Result(key, count));
    }
}
```

#### 2. Implement Deduplication Logic
```java
public class DeduplicateProcessor 
    extends KeyedProcessFunction<String, Event, Event> {
    
    private ValueState<Set<String>> seenIdsState;

    @Override
    public void open(Configuration parameters) {
        seenIdsState = getRuntimeContext().getState(
            new ValueStateDescriptor<>("seenIds", new SetTypeInfo<>(String.class)));
    }

    @Override
    public void processElement(Event event, Context ctx, Collector<Event> out) 
        throws Exception {
        Set<String> seenIds = seenIdsState.value();
        if (seenIds == null) {
            seenIds = new HashSet<>();
        }
        
        if (!seenIds.contains(event.getId())) {
            seenIds.add(event.getId());
            seenIdsState.update(seenIds);
            out.collect(event);
        }
    }
}
```

#### 3. Implement Window Aggregation
```java
DataStream<Event> stream = ...;
stream.keyBy(Event::getKey)
      .window(TumblingEventTimeWindows.of(Time.minutes(1)))
      .aggregate(new AggregateFunction<Event, Long, Long>() {
          @Override
          public Long createAccumulator() { return 0L; }
          
          @Override
          public Long add(Event event, Long acc) { return acc + 1; }
          
          @Override
          public Long getResult(Long acc) { return acc; }
          
          @Override
          public Long merge(Long acc1, Long acc2) { return acc1 + acc2; }
      });
```

---

## üéì Learning Resources Quick Reference

### Official Documentation
- Flink Official Site: https://flink.apache.org/
- Flink Chinese Docs: https://flink.apache.org/zh/
- Kafka Official Site: https://kafka.apache.org/

### Recommended Books
- "Flink in Action and Performance Optimization"
- "Streaming Systems"
- "Designing Data-Intensive Applications" (DDIA)

### Community
- Apache Flink Chinese Community
- Stack Overflow (tag: apache-flink)
- GitHub Discussions

---

## ‚ö° Quick Memory Mnemonics

### Project Architecture (3-3-3)
- **3 Tiers**: outer, flink, common
- **3 Jobs**: Orderbook, Ticker, Candle
- **3 Components**: Flink, Kafka, Redis

### Flink State (MVLRA)
- **M**apState - Map structure
- **V**alueState - Single value
- **L**istState - List
- **R**educingState - Accumulating
- **A**ggregatingState - Aggregating

### Optimization Methods (Parallelism-State-Network-Chain-Skew-Async)
- **Parallelism**
- **State** optimization
- **Network** optimization
- **Chain** optimization
- Data **Skew**
- **Async** IO

### Troubleshooting Process (Phenomenon-Log-Kafka-Upstream-Dependency)
- Confirm **Phenomenon**
- Check **Logs**
- Check **Kafka**
- Check **Upstream** (market-outer)
- Check **Dependencies** (Redis/Zookeeper)

---

## üìû Project Contact Info Quick Reference

### Component Ports
- Flink Web UI: `http://localhost:8081`
- Flink RPC: `6123`
- Kafka: `localhost:9092`
- Zookeeper: `localhost:2181`
- Redis: `localhost:6379`
- market-outer: `http://localhost:10808`

### Common Commands
```bash
# Start Flink
$FLINK_HOME/bin/start-cluster.sh

# Submit job
flink run -c com.ganten.market.flink.job.OrderbookJob market-flink.jar

# Check Kafka consumer group
kafka-consumer-groups.sh --describe --group orderbook --bootstrap-server localhost:9092

# Redis query
redis-cli GET orderbook:1:1

# List Flink jobs
flink list
```

---

## üí° Interview Bonus Points

### Demonstrate Depth of Thinking
1. Propose improvement suggestions (async IO, incremental output)
2. Discuss edge cases (data loss, out-of-order)
3. Compare different approaches (Flink vs Spark, Redis vs MySQL)

### Demonstrate Project Understanding
1. Draw architecture diagram
2. Explain key code
3. Analyze performance bottlenecks

### Demonstrate Technical Breadth
1. Mention monitoring solutions (Prometheus, Grafana)
2. Discuss scalability (horizontal scaling, multi-datacenter)
3. Focus on cost optimization (resource quotas, on-demand scaling)

---

## ‚úÖ Pre-Interview Final Checklist

### Technical Preparation
- [ ] Can fluently introduce project (3-minute version)
- [ ] Can hand-draw architecture diagram
- [ ] Familiar with OrderBookProcessor core code
- [ ] Understand Flink State and Checkpoint mechanisms
- [ ] Prepare 2-3 technical challenge stories (STAR method)
- [ ] Understand common failure troubleshooting process

### Environment Preparation
- [ ] Project code can run locally
- [ ] Prepare architecture diagram PPT/whiteboard sketch
- [ ] Prepare code snippets (GitHub Gist)
- [ ] Prepare performance data (if available)

### Mental Preparation
- [ ] Confident but not arrogant
- [ ] Say "I don't know" when you don't, but state learning plan
- [ ] Interview is two-way selection
- [ ] Deep breath, stay calm

---

**Believe in yourself, you can do it! üéâ**
