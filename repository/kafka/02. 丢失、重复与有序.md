# 一、消息不丢失（At-least-once）

### 1️⃣ Producer 侧

关键配置只有三个：

```
acks = all
retries > 0
enable.idempotence = true
```

含义：

| 名称 | 含义                               |
| ---- | ---------------------------------- |
| ISR  | In-Sync Replicas（同步副本）       |
| OSR  | Out-of-Sync Replicas（不同步副本） |


* `acks=all`：ISR 全部写入成功才算成功
* `retries`：网络抖动可重试
* `idempotence`：防止重试导致重复写

前提：

* `min.insync.replicas >= 2`
* replication.factor ≥ 3（生产环境）

这一步保证 **broker 不丢**

---

### 2️⃣ Broker 侧

* 副本同步（ISR）
* Leader 挂了从 ISR 选
* 日志顺序写盘

风险点：

* `unclean.leader.election=true` → **会丢数据**
* 必须关掉

---

### 3️⃣ Consumer 侧（最容易丢）

错误示例：

```
enable.auto.commit = true
```

正确姿势：

```
enable.auto.commit = false
```

流程：

```
poll()
处理业务
提交 offset（commit）
```

**先处理，再提交**

---

## 不丢失总结

| 环节     | 关键点             |
| -------- | ------------------ |
| Producer | acks=all + 幂等    |
| Broker   | ISR + 禁止 unclean |
| Consumer | 手动提交 offset    |

---

# 二、消费不重复（Exactly-once / 幂等）

先说实话：

> **Kafka 本身只能保证“不会多写”，不能保证“不会多消费”**

所以要拆开看。

---

## 1️⃣ Producer 不重复写

```
enable.idempotence = true
```

Kafka 会给 producer：

* PID
* sequence number

Broker 自动去重

✔️ **写入端 exactly-once**

---

## 2️⃣ Consumer 不重复消费

Kafka 只能做到：

* **at-least-once**
* 或 **at-most-once**

**“不重复消费”一定是业务保证的。**

### 常见工程解法

#### 解法 1：业务幂等（最常见）

* 业务表唯一键
* 消息带唯一 ID（orderId / tradeId）
* 重复处理直接 ignore

```
INSERT ... ON DUPLICATE KEY IGNORE
```

---

#### 解法 2：消费成功 + 原子提交

```
处理消息
写 DB
提交 offset
```

但：

* 进程崩溃在中间 → 仍可能重复

---

#### 解法 3：Kafka 事务（高阶）

适合：

* **Kafka → Kafka**
* 流处理 / Flink / Kafka Streams

```
consume
process
produce
commit transaction
```

但：

* 不适合 Kafka → DB
* 运维复杂

---

## 结论

> **消费端 exactly-once ≈ 业务幂等**

---

# 三、消息有序（Ordering）

### 关键事实

> **Kafka 只保证“单 partition 内有序”**

---

## 1️⃣ 如何保证顺序？

### Producer 侧

```
同一业务 key → 同一个 partition
```

比如：

```
orderId % partitionCount
```

Kafka：

```
key 相同 → hash → partition 相同
```

---

## 2️⃣ Consumer 侧

**一个 partition 只能给一个 consumer**

```
Consumer Group
└─ Partition 0 → Consumer A
```

不要：

* 多线程并行处理同一 partition
* 异步乱序提交 offset

---

## 3️⃣ 会破坏顺序的操作

多线程处理同一 partition
消费失败跳过提交
人工 seek offset
分区 reassign 时业务没兜底

---

## 顺序保证总结

| 层面     | 要求                    |
| -------- | ----------------------- |
| Producer | 相同 key → 同 partition |
| Topic    | partition 数固定        |
| Consumer | 单线程处理单 partition  |

---

# 四、三个目标放一起，看真实结论

| 目标   | Kafka 能否原生保证 |
| ------ | ------------------ |
| 不丢失 | 可以             |
| 不重复 | 需业务配合       |
| 有顺序 | 单 partition     |

### 真正工程上的“黄金组合”

```
Producer:
  acks=all
  enable.idempotence=true

Topic:
  replication.factor=3
  min.insync.replicas=2

Consumer:
  enable.auto.commit=false
  单 partition 单线程
  业务幂等
```

---

## 总结

> Kafka 能保证：
> **消息写进去不丢、按分区顺序存**
>
> 但**消费是否重复、是否乱序，本质是你代码的事**。
>
> 想要“看起来完全正确”，唯一靠谱的方案就是：
> **业务幂等 + 正确的 offset 提交策略。**
