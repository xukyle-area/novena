# Java HashMap – Detailed Implementation and Design

## 1. What is HashMap

`HashMap` is a hash table–based implementation of the `Map` interface in Java. It stores key–value pairs and provides **average O(1)** time complexity for `put`, `get`, and `remove` operations.

Key characteristics:

* Allows **null keys and null values** (one null key allowed)
* Not thread-safe
* No ordering guarantee
* Performance depends heavily on hash distribution

---

## 2. Core Data Structure

At a high level, HashMap consists of:

* An **array** (table)
* Each array element is a **bucket**
* Each bucket stores:

  * A linked list (JDK 7)
  * A linked list or a red-black tree (JDK 8+)

```text
Node<K,V>[] table
```

Each node contains:

* key
* value
* hash
* next reference

---

## 3. Hash Function Design

### 3.1 hash() Method

In JDK 8, HashMap applies a **secondary hash** to reduce collisions:

```java
h ^ (h >>> 16)
```

Purpose:

* Spread high bits into low bits
* Improve bucket distribution when table size is small

---

### 3.2 Index Calculation

```text
index = (n - 1) & hash
```

Requirements:

* `n` (table length) must be a power of 2

Benefits:

* Faster than modulo
* Ensures uniform distribution

---

## 4. Put Operation Workflow

### 4.1 Steps

1. Compute hash(key)
2. Locate bucket index
3. If bucket empty → insert node
4. If bucket not empty:

   * Traverse nodes
   * If key exists → replace value
   * Else → append node
5. If chain length exceeds threshold → treeify
6. If size exceeds threshold → resize

---

### 4.2 Collision Handling

* JDK 7: linked list only
* JDK 8+:

  * Linked list → red-black tree

Treeification conditions:

* Bucket size ≥ 8
* Table size ≥ 64

---

## 5. Get Operation Workflow

1. Compute hash(key)
2. Locate bucket index
3. If bucket empty → return null
4. Traverse list or tree
5. Match key via `equals()`

Time complexity:

* Average: O(1)
* Worst-case:

  * JDK 7: O(n)
  * JDK 8+: O(log n)

---

## 6. Resize (Rehash) Mechanism

### 6.1 Capacity and Load Factor

Default values:

* Initial capacity: 16
* Load factor: 0.75

Resize condition:

```text
size > capacity * loadFactor
```

---

### 6.2 Resize Process

* Capacity doubles
* Nodes redistributed
* JDK 8 optimization:

  * No rehash computation
  * Node stays at index or moves by oldCap

---

## 7. Treeification and Untreeification

### 7.1 Why Treeify

Linked lists degrade to O(n) under heavy collision.

Red-black trees guarantee:

* O(log n) lookup
* Balanced structure

---

### 7.2 Untreeify Conditions

When resizing reduces bucket size below:

```text
UNTREEIFY_THRESHOLD = 6
```

Tree converts back to linked list.

---

## 8. Null Key Handling

* HashMap allows **one null key**
* Null key hash is defined as 0
* Always stored in bucket index 0

---

## 9. Equals and HashCode Contract

Correct behavior requires:

* If `equals()` returns true → `hashCode()` must be equal
* Hash collisions allowed
* Poor hashCode leads to performance degradation

Common mistake:

* Overriding `equals()` without `hashCode()`

---

## 10. Fail-Fast Mechanism

Iterators are **fail-fast**:

* Structural modification increments `modCount`
* Iterator checks consistency
* Throws `ConcurrentModificationException`

Not a concurrency guarantee.

---

## 11. Thread Safety Issues

HashMap is **not thread-safe**:

* Concurrent put may cause data loss
* JDK 7: possible infinite loop during resize
* JDK 8: structural corruption still possible

Alternatives:

* `Collections.synchronizedMap`
* `ConcurrentHashMap`

---

## 12. Time Complexity Summary

| Operation | Average | Worst Case |
| --------- | ------- | ---------- |
| get       | O(1)    | O(log n)   |
| put       | O(1)    | O(log n)   |
| remove    | O(1)    | O(log n)   |

---

## 13. Common Interview Topics

* Why capacity must be power of 2
* Difference between JDK 7 and JDK 8
* Treeification thresholds
* Resize optimization
* Hash collision handling

---

## 14. Summary

HashMap is a carefully engineered balance between speed, memory usage, and collision handling. JDK 8 significantly improved worst-case performance by introducing red-black trees while preserving O(1) average complexity. Correct usage depends on proper `hashCode` implementation and awareness of concurrency limitations.
