# Apache Flink 基础概念

> Apache Flink 是一个开源的分布式流处理框架，用于在无界和有界数据流上进行有状态的计算。

---

## 一、Flink 核心概念

### 1. Stream（流）

**Streams** 流，是 Flink 处理的核心数据抽象，分为有限数据流与无限数据流：

- **`Unbounded Stream`（无界流）**：有始无终的数据流，即无限数据流
- **`Bounded Stream`（有界流）**：限定大小、有始有终的数据集合，即有限数据流

**两者的区别：**

| 特性     | 无界流                   | 有界流                  |
| -------- | ------------------------ | ----------------------- |
| 数据量   | 随时间持续增加           | 固定大小                |
| 计算状态 | 持续进行，无结束状态     | 最终完成并结束          |
| 对应场景 | **流处理任务（Stream）** | **批处理任务（Batch）** |

**Flink 的核心设计理念：**
> "批处理是流处理的特殊情况"（Batch is a special case of Streaming）

这意味着：
- **批处理**：处理已知大小的固定数据集，有明确的开始和结束，处理完成后任务终止
- **流处理**：持续处理不断产生的数据流，没有结束状态，任务一直运行

---

### 2. State（状态）

**State（状态）** 是计算过程中需要保存的数据信息，在容错恢复和 Checkpoint 中扮演重要角色。

#### 2.1 为什么需要 State？

**1. 增量处理（Incremental Processing）**

流计算本质上是增量处理，数据来一条处理一条，逐步累积计算结果：

```text
批量处理：等所有数据到齐 → 一次性全部处理 → 输出结果
例如：统计昨天全天的订单总额
[订单1, 订单2, ..., 订单10000] → SUM() → 结果

增量处理：来一条数据 → 更新结果 → 来一条 → 再更新 → ...
例如：实时统计今天的订单总额
订单1(100元) → 当前总额: 100
订单2(200元) → 当前总额: 300  ← 基于上一次的结果增量更新
订单3(50元)  → 当前总额: 350
```

增量处理时，**每次计算都需要"上一次的结果"**，这就是 State。

**State 应用示例：**

| 场景     | State 内容     | 增量处理逻辑                     |
| -------- | -------------- | -------------------------------- |
| 累加求和 | 当前总和值     | 新值 = 旧 State + 新数据         |
| 计数器   | 当前计数       | 新计数 = 旧 State + 1            |
| 最大值   | 当前最大值     | 新最大值 = max(旧 State, 新数据) |
| UV 统计  | 已访问用户集合 | 检查新用户是否在旧 State 中      |
| 会话窗口 | 用户会话信息   | 更新会话开始/结束时间            |

**2. Exactly-Once 语义保证**

为了确保 **Exactly-Once**（精确一次）语义，数据需要能够写入到状态中。持久化存储能够保证在整个分布式系统运行失败或挂掉的情况下，仍然做到 Exactly-Once。

#### 2.2 处理语义（Processing Guarantees）

Flink 支持三种数据处理语义：

| 语义              | 解释     | 含义                         | 适用场景                               |
| ----------------- | -------- | ---------------------------- | -------------------------------------- |
| **At-Most-Once**  | 最多一次 | 数据可能丢失，但不会重复处理 | 允许丢数据的场景（如日志采集）         |
| **At-Least-Once** | 至少一次 | 数据不会丢失，但可能重复处理 | 可以容忍重复的场景                     |
| **Exactly-Once**  | 精确一次 | 数据既不丢失也不重复         | 金融交易、账单统计等精确性要求高的场景 |

**分布式系统中的挑战：**
- 处理到一半崩溃
- 数据已发出，但 Flink 认为没处理，再处理一次导致重复

**实现 Exactly-Once 的机制：**
1. **Checkpoint 机制**（内部状态）：定期保存所有算子的 State 快照到可靠存储
2. **两阶段提交**（外部系统）：对于写入外部系统（如数据库、Kafka），使用事务保证

**关键要点：**
- Flink 通过 Checkpoint 保存 State，崩溃后能精确恢复到某个时间点
- 结合事务机制，确保数据写入外部系统也是精确一次
- 需要数据源支持重放（如 Kafka 的 offset）

#### 2.3 State 类型

Flink 提供了多种类型的 State：

| State 类型           | 说明                | 适用场景           |
| -------------------- | ------------------- | ------------------ |
| **ValueState**       | 存储单个值          | 计数器、累加器     |
| **ListState**        | 存储元素列表        | 收集一批数据后处理 |
| **MapState**         | 存储 Key-Value 映射 | 用户会话管理、去重 |
| **ReducingState**    | 存储聚合后的单个值  | 求和、求最大值     |
| **AggregatingState** | 存储聚合结果        | 复杂的聚合逻辑     |

---

### 3. Time（时间）

时间是判断业务状态是否滞后、数据处理是否及时的重要依据。Flink 支持三种时间语义：

#### 3.1 三种时间类型

**1. Event Time（事件时间）**

**数据真正产生的时间**（业务发生的时间）

```text
例如：用户在 10:00:00 点击了购买按钮
     → Event Time = 10:00:00
     
即使这条数据因为网络延迟在 10:05:00 才到达 Flink，
Event Time 仍然是 10:00:00
```

**特点：**
- 时间戳在数据产生时就确定了，嵌入在数据本身中
- 不受网络延迟、处理延迟影响
- **最准确反映业务真实情况**

**2. Ingestion Time（摄取时间）**

**数据进入 Flink 系统的时间**（到达 Source 的时间）

```text
例如：数据在 10:00:00 产生
     因为网络延迟，10:05:00 才到达 Flink
     → Ingestion Time = 10:05:00
```

**特点：**
- 在 Source 算子处自动分配时间戳
- 介于 Event Time 和 Processing Time 之间
- 相对稳定，但不反映真实业务时间

**3. Processing Time（处理时间）**

**Flink 算子实际处理数据的时间**（机器时钟时间）

```text
例如：数据在 10:00:00 产生
     10:05:00 到达 Flink
     10:06:30 被某个算子处理
     → Processing Time = 10:06:30
```

**特点：**
- 取决于系统处理速度
- 最简单，性能最好（无需处理乱序）
- **最不准确**，完全依赖处理速度

#### 3.2 时间对比示例

假设统计 **10:00-10:05 这 5 分钟的订单金额**：

| 订单数据 | Event Time | Ingestion Time | Processing Time | 说明             |
| -------- | ---------- | -------------- | --------------- | ---------------- |
| 订单A    | 10:02:00   | 10:02:10       | 10:02:15        | 正常到达         |
| 订单B    | 10:03:00   | 10:03:05       | 10:03:10        | 正常到达         |
| 订单C    | 10:04:30   | 10:08:00       | 10:08:05        | 网络延迟，迟到了 |

**使用不同时间的结果：**

```text
Event Time:      订单A、B、C 都算在 10:00-10:05 窗口 ✅ 符合业务逻辑
Ingestion Time:  订单C 算在 10:05-10:10 窗口 ⚠️  不太准确
Processing Time: 订单C 算在 10:05-10:10 窗口 ⚠️  完全不准确
```

#### 3.3 时间的重要性

**a. 判断业务状态是否滞后**

```text
假设现在真实时间是 11:00
Flink 正在处理 Event Time = 10:30 的数据

→ 说明数据处理滞后了 30 分钟
→ 需要优化性能或增加资源
```

**b. 窗口计算的准确性**

```text
业务需求：统计每小时的销售额

使用 Event Time:
  → 按照订单真实发生时间统计 ✅ 准确

使用 Processing Time:
  → 按照系统处理时间统计 ❌ 网络延迟会导致统计错误
```

**c. 处理乱序数据**

```text
数据到达顺序: 订单2(10:05) → 订单1(10:03) → 订单3(10:08)
             ↑ 乱序了！

Event Time 模式：
  → Flink 可以根据 Event Time 重新排序
  → 配合 Watermark 机制，正确处理延迟数据
```

#### 3.4 选择建议

| 场景                 | 推荐时间类型        | 原因                   |
| -------------------- | ------------------- | ---------------------- |
| 金融交易、账单统计   | **Event Time**      | 必须按真实业务时间计算 |
| 实时监控（允许误差） | **Processing Time** | 性能最好，实现简单     |
| 快速原型开发         | **Ingestion Time**  | 折中方案               |

**核心原则：** 需要准确反映业务逻辑时，使用 **Event Time**；只关心系统处理性能时，使用 **Processing Time**。

---

### 4. Watermark（水印）

**Watermark** 是 Flink 用于处理乱序数据和触发窗口计算的机制。

#### 4.1 什么是 Watermark？

Watermark 是一个时间戳，表示"**小于等于这个时间的事件都已经到达**"。

```text
Watermark(T) 表示：时间戳 ≤ T 的所有数据都已经到达
```

**例如：**
```text
Watermark(10:05:00) 表示：
  → 10:05:00 之前的数据都已经到达
  → 可以安全地触发 [10:00-10:05] 窗口的计算
```

#### 4.2 为什么需要 Watermark？

在 Event Time 模式下，数据可能乱序到达：

```text
时间线：
  → 数据1: Event Time = 10:01  ✓ 到达
  → 数据2: Event Time = 10:05  ✓ 到达
  → 数据3: Event Time = 10:03  ⚠️  迟到了！

问题：什么时候可以触发 [10:00-10:05] 窗口的计算？
     如果立即触发，数据3 会被遗漏！
```

**Watermark 的作用：**
- 告诉 Flink 何时可以安全地触发窗口计算
- 允许一定程度的数据延迟
- 平衡结果准确性和延迟之间的关系

#### 4.3 Watermark 策略

**1. 固定延迟 Watermark**

```java
// 允许最多 5 秒的数据延迟
WatermarkStrategy
    .forBoundedOutOfOrderness(Duration.ofSeconds(5))
    .withTimestampAssigner((event, timestamp) -> event.getTimestamp());
```

```text
当前最大 Event Time = 10:05:00
Watermark = 10:05:00 - 5秒 = 10:04:55

含义：10:04:55 之前的数据都已到达
```

**2. 单调递增 Watermark**

```java
// 假设数据完全有序，无延迟
WatermarkStrategy
    .forMonotonousTimestamps()
    .withTimestampAssigner((event, timestamp) -> event.getTimestamp());
```

适用于数据完全按时间顺序到达的场景。

#### 4.4 Watermark 与窗口触发

```text
窗口：[10:00:00 - 10:05:00]

事件流：
  Event1: EventTime=10:01:00  Watermark=10:01:00
  Event2: EventTime=10:03:00  Watermark=10:03:00
  Event3: EventTime=10:06:00  Watermark=10:06:00  ← 触发窗口！
  
当 Watermark ≥ 窗口结束时间（10:05:00）时，窗口被触发
```

**迟到数据处理：**
- 如果数据在 Watermark 之后才到达，可以通过 **Allowed Lateness** 机制继续处理
- 或者通过 **Side Output** 将迟到数据输出到另一个流

---

### 5. Window（窗口）

**Window** 将无界流切分成有界的数据块，以便进行聚合计算。

#### 5.1 窗口类型

**1. Tumbling Window（滚动窗口）**

固定大小、无重叠的窗口。

```text
窗口大小：5分钟

时间线：
[10:00-10:05] [10:05-10:10] [10:10-10:15] [10:15-10:20]
    窗口1        窗口2        窗口3        窗口4
```

**代码示例：**
```java
stream
    .keyBy(...)
    .window(TumblingEventTimeWindows.of(Time.minutes(5)))
    .sum("value");
```

**应用场景：** 每 5 分钟统计一次销售额、每小时统计一次 PV

---

**2. Sliding Window（滑动窗口）**

固定大小、有重叠的窗口。

```text
窗口大小：10分钟，滑动间隔：5分钟

时间线：
[10:00-10:10]
     [10:05-10:15]
          [10:10-10:20]
               [10:15-10:25]
```

**代码示例：**
```java
stream
    .keyBy(...)
    .window(SlidingEventTimeWindows.of(Time.minutes(10), Time.minutes(5)))
    .sum("value");
```

**应用场景：** 计算最近 10 分钟的移动平均值、实时监控最近 N 分钟的指标

---

**3. Session Window（会话窗口）**

根据数据间隔动态生成窗口，无固定大小。

```text
Session Gap：5分钟（如果 5 分钟内没有新数据，会话结束）

事件流：
Event1: 10:00  ─┐
Event2: 10:02   ├─ Session 1: [10:00-10:07]
Event3: 10:04  ─┘  （最后一个事件是 10:04，等待 5 分钟到 10:09）

Event4: 10:15  ─┐
Event5: 10:16   ├─ Session 2: [10:15-10:21]
Event6: 10:18  ─┘
```

**代码示例：**
```java
stream
    .keyBy(...)
    .window(EventTimeSessionWindows.withGap(Time.minutes(5)))
    .sum("value");
```

**应用场景：** 用户会话分析、网站访问行为分析

---

**4. Global Window（全局窗口）**

所有数据在一个窗口中，需要自定义触发器。

**应用场景：** 自定义复杂的窗口逻辑

#### 5.2 窗口函数

| 函数类型                  | 说明                               | 使用场景                 |
| ------------------------- | ---------------------------------- | ------------------------ |
| **ReduceFunction**        | 增量聚合，每来一条数据更新一次结果 | 求和、求最大值           |
| **AggregateFunction**     | 更灵活的增量聚合                   | 平均值、复杂聚合         |
| **ProcessWindowFunction** | 访问窗口所有元素和元数据           | 需要窗口信息、排序、去重 |

---

### 6. API 层次

Flink 的 API 分为三层，像一个**金字塔结构**，从上到下在"易用性"和"灵活性"之间做权衡：

```text
        ┌─────────────────────┐
        │   SQL / Table API   │  ← 最抽象，最易用，功能受限
        ├─────────────────────┤
        │   DataStream API    │  ← 平衡抽象和灵活性
        ├─────────────────────┤
        │  ProcessFunction    │  ← 最灵活，最底层，需要自己实现
        └─────────────────────┘
```

#### 6.1 核心概念对比

| 维度     | 抽象能力                   | 表达能力             |
| -------- | -------------------------- | -------------------- |
| **含义** | 隐藏底层细节，提供高级语法 | 能实现复杂逻辑的能力 |
| **类比** | 自动挡汽车（简单）         | 手动挡汽车（灵活）   |

**权衡关系：**
- **抽象能力越强** → 使用越简单，但能做的事情越受限
- **表达能力越强** → 能做的事情越多，但需要写更多代码

#### 6.2 SQL / Table API（最抽象）

**特点：** 用 SQL 或类 SQL 语法操作数据，像操作数据库表一样。

```sql
-- 统计每个商品类型的销售总额
SELECT 
    product_type, 
    SUM(price) as total 
FROM orders 
GROUP BY product_type
```

**优势：**
- ✅ 抽象能力强：不需要了解流处理细节
- ✅ 门槛低：会 SQL 就能用
- ✅ 自动优化：Flink 会优化执行计划

**劣势：**
- ❌ 表达能力弱：只能做标准的 SQL 操作
- ❌ 无法实现复杂逻辑：如自定义状态管理

**适用场景：** 标准的 ETL、报表统计、简单数据分析

#### 6.3 DataStream API（平衡）

**特点：** 用 Java/Scala 等编程语言操作数据流，提供丰富的算子。

```java
// 统计每个商品类型的销售总额
stream
    .keyBy(order -> order.productType)
    .sum("price")
    .print();
```

**优势：**
- ✅ 灵活性较高：可以自定义函数、状态、窗口
- ✅ 抽象适中：提供常用算子（map、filter、window 等）
- ✅ 能处理复杂场景：多流 join、自定义窗口

**劣势：**
- ❌ 需要编程基础
- ❌ 某些极端场景受限：如精确控制定时器

**适用场景：** 大部分流处理业务（实时风控、实时推荐、CEP）

#### 6.4 ProcessFunction（最底层）

**特点：** 直接操作底层 API，可以访问状态、定时器、事件时间等所有细节。

```java
public class MyProcessFunction extends KeyedProcessFunction<String, Event, Result> {
    
    private ValueState<Long> countState;
    
    @Override
    public void processElement(Event event, Context ctx, Collector<Result> out) {
        // 读取状态
        Long count = countState.value();
        if (count == null) count = 0L;
        
        // 更新状态
        count++;
        countState.update(count);
        
        // 注册定时器（10秒后触发）
        ctx.timerService().registerEventTimeTimer(ctx.timestamp() + 10000);
        
        // 输出结果
        out.collect(new Result(event.key, count));
    }
    
    @Override
    public void onTimer(long timestamp, OnTimerContext ctx, Collector<Result> out) {
        // 定时器触发时执行（如清理过期状态）
        countState.clear();
    }
}
```

**优势：**
- ✅ 表达能力最强：可以实现任何复杂逻辑
- ✅ 完全控制：状态、定时器、侧输出流、水印等全部可控
- ✅ 极致性能优化

**劣势：**
- ❌ 抽象能力最弱：所有细节都要自己处理
- ❌ 代码复杂：需要深入理解 Flink 内部机制
- ❌ 容易出错

**适用场景：** 极端复杂的业务逻辑、需要精细控制的场景

#### 6.5 如何选择

| API 层次            | 适用场景                   | 开发成本   |
| ------------------- | -------------------------- | ---------- |
| **SQL / Table API** | 简单的 ETL、报表、数据分析 | 最低 ⭐     |
| **DataStream API**  | 大部分实时计算业务         | 中等 ⭐⭐⭐   |
| **ProcessFunction** | 极端复杂的自定义逻辑       | 最高 ⭐⭐⭐⭐⭐ |

**建议：**
- 优先用 **SQL / Table API**（能解决 80% 的场景）
- 需要灵活性时用 **DataStream API**
- 只有无法用上层 API 实现时，才用 **ProcessFunction**

---

## 二、Flink 架构

### 1. 架构组件

Flink 采用经典的 **Master-Worker** 架构：

```text
┌─────────────────────────────────────────────────┐
│                 Client（客户端）                   │
│            提交作业、查看状态                       │
└────────────────┬────────────────────────────────┘
                 │
                 ▼
┌─────────────────────────────────────────────────┐
│            JobManager（主节点）                    │
│  - 资源管理  - 任务调度  - Checkpoint 协调         │
└────────┬───────────────────────┬────────────────┘
         │                       │
         ▼                       ▼
┌──────────────────┐    ┌──────────────────┐
│  TaskManager 1   │    │  TaskManager 2   │
│   - 执行任务     │    │   - 执行任务     │
│   - 管理内存     │    │   - 管理内存     │
│   - 网络通信     │    │   - 网络通信     │
└──────────────────┘    └──────────────────┘
```

#### 1.1 JobManager（作业管理器）

**职责：**
- **资源管理**：管理 TaskManager 的资源分配
- **任务调度**：将作业的算子分配到 TaskManager 执行
- **Checkpoint 协调**：触发和协调 Checkpoint
- **故障恢复**：监控 TaskManager，处理故障恢复

**关键组件：**
- **ResourceManager**：资源管理
- **Dispatcher**：接收作业提交
- **JobMaster**：管理单个作业的执行

#### 1.2 TaskManager（任务管理器）

**职责：**
- **执行任务**：执行具体的算子逻辑
- **管理内存**：管理堆内存、堆外内存、网络缓冲区
- **数据交换**：在算子之间传输数据
- **状态存储**：本地存储算子的 State

**关键概念：**
- **Task Slot**：TaskManager 的资源单位，每个 Slot 可以运行一个任务
- **并行度**：决定了需要多少个 Task Slot

---

### 2. 作业执行流程

```text
1. 编写代码
   ↓
2. 提交作业到 JobManager
   ↓
3. JobManager 生成执行图（ExecutionGraph）
   ↓
4. JobManager 分配资源（Task Slots）
   ↓
5. TaskManager 执行任务
   ↓
6. 数据在算子之间流动
   ↓
7. 结果输出
```

#### 2.1 执行图转换

Flink 将用户程序转换为多层执行图：

```text
StreamGraph（流图）
    ↓ 优化
JobGraph（作业图）
    ↓ 并行化
ExecutionGraph（执行图）
    ↓ 部署
物理执行图
```

---

### 3. 并行度与 Task Slot

#### 3.1 并行度（Parallelism）

**并行度** 决定了算子的任务实例数量。

```java
// 设置全局并行度
env.setParallelism(4);

// 设置算子并行度
stream
    .map(...).setParallelism(2)
    .keyBy(...)
    .sum(...).setParallelism(4);
```

**例如：** 并行度为 4 的 `map` 算子，会创建 4 个 `map` 任务实例。

#### 3.2 Task Slot

**Task Slot** 是 TaskManager 的资源分片。

```text
TaskManager (8 CPU, 32GB 内存)
├─ Task Slot 1 (2 CPU, 8GB)
├─ Task Slot 2 (2 CPU, 8GB)
├─ Task Slot 3 (2 CPU, 8GB)
└─ Task Slot 4 (2 CPU, 8GB)
```

**Slot Sharing（插槽共享）：**
- 来自同一个作业的不同算子可以共享同一个 Slot
- 减少资源浪费，提高资源利用率

```text
Slot 1:
  ├─ Source 任务
  ├─ Map 任务
  └─ Sink 任务
```

---

### 4. Checkpoint 机制

**Checkpoint** 是 Flink 实现容错的核心机制。

#### 4.1 Checkpoint 流程

```text
1. JobManager 触发 Checkpoint
   ↓
2. Source 算子插入 Checkpoint Barrier
   ↓
3. Barrier 随数据流向下游传递
   ↓
4. 算子收到 Barrier 后，保存自己的 State
   ↓
5. State 写入 StateBackend（如 HDFS）
   ↓
6. 所有算子完成后，Checkpoint 成功
```

#### 4.2 Checkpoint Barrier

**Barrier** 是插入数据流中的特殊标记，用于对齐 Checkpoint。

```text
Source ─→ Map ─→ KeyBy ─→ Sum ─→ Sink

数据流：
  [数据1] [数据2] [Barrier-1] [数据3] [数据4] [Barrier-2] ...
```

当算子收到 Barrier 时，会保存当前状态。

#### 4.3 StateBackend

**StateBackend** 决定了 State 的存储位置：

| StateBackend            | 存储位置                   | 适用场景     |
| ----------------------- | -------------------------- | ------------ |
| **MemoryStateBackend**  | JobManager 内存            | 开发测试     |
| **FsStateBackend**      | 文件系统（HDFS）           | 一般生产环境 |
| **RocksDBStateBackend** | RocksDB（本地） + 文件系统 | 大状态场景   |

```java
// 配置 StateBackend
env.setStateBackend(new FsStateBackend("hdfs://..."));
env.enableCheckpointing(60000); // 每 60 秒一次 Checkpoint
```

---

### 5. 算子链（Operator Chaining）

**算子链** 是 Flink 的优化机制，将多个算子合并在一起执行，减少数据传输开销。

```text
未优化：
Source ──网络──→ Map ──网络──→ Filter ──网络──→ Sink

优化后（算子链）：
Source → Map → Filter  ──网络──→ Sink
    (同一个线程)
```

**条件：**
- 算子在同一个 Task Slot
- 并行度相同
- 连接方式为 Forward（一对一）

**禁用算子链：**
```java
stream.map(...).disableChaining();  // 禁用当前算子的链接
stream.map(...).startNewChain();    // 从当前算子开始新链
```

---

## 三、Flink 应用场景

| 场景         | 说明                 | 示例                   |
| ------------ | -------------------- | ---------------------- |
| **实时 ETL** | 数据清洗、转换、加载 | 日志采集、数据同步     |
| **实时报表** | 实时指标统计         | 实时大屏、业务监控     |
| **实时告警** | 异常检测与告警       | 系统监控、风控预警     |
| **实时推荐** | 实时特征计算         | 电商推荐、内容推荐     |
| **实时风控** | 欺诈检测、风险评估   | 支付风控、信贷风控     |
| **CEP**      | 复杂事件处理         | 用户行为分析、异常检测 |
| **机器学习** | 在线学习、特征工程   | 实时模型推理           |

---

## 四、总结

### Flink 核心优势

1. **统一批流处理**：用同一套 API 处理批和流
2. **强大的状态管理**：支持大规模状态存储
3. **精确一次语义**：端到端的 Exactly-Once 保证
4. **低延迟高吞吐**：毫秒级延迟，百万级吞吐
5. **灵活的窗口机制**：支持多种窗口类型
6. **Event Time 支持**：正确处理乱序数据
7. **强大的容错能力**：自动故障恢复

---

**参考资源：**
- [Apache Flink 官方文档](https://flink.apache.org/)
- [Flink GitHub](https://github.com/apache/flink)
- [Flink 中文社区](https://flink-china.org/)
